{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Исследование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных, предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классические"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Линейная регрессия с L2-регуляризацией.\n",
    "from sklearn.linear_model import Ridge\n",
    "# Случайный лес.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Бустниги.\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Мультитаргет-регрессия.\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример мультитаргет-регрессия.\n",
    "ridge = Ridge()\n",
    "model = MultiOutputRegressor(estimator=ridge)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Training score:\", score)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мета-алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Голосование.\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "# Пример.\n",
    "voting_algorithm = VotingRegressor(\n",
    "    [('CB', CatBoostRegressor()), ('XGB', XGBRegressor())]\n",
    ")\n",
    "\n",
    "y_pred = voting_algorithm.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бэггинг.\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "# Пример.\n",
    "bagging = BaggingRegressor(base_estimator=Ridge(), n_estimators=10, random_state=0).fit(X, y)\n",
    "\n",
    "y_pred = bagging.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стэкинг.\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "# Пример.\n",
    "estimators = [\n",
    "    ('CB', CatBoostRegressor()),\n",
    "    ('XGB', XGBRegressor())\n",
    "]\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    inal_estimator=RandomForestRegressor(n_estimators=10, random_state=42)\n",
    ")\n",
    "\n",
    "reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evraz_metric(answers: pd.DataFrame, user_csv: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Метрика оценки качества модели, предложенная организаторами EVRAZ.\n",
    "    :param answers: pd.DataFrame, датасет с реальными значениями целевых переменных.\n",
    "    :param user_csv: pd.DataFrame, датасет с предсказанными значениями целевых переменных.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Содержание углерода в металле.\n",
    "    delta_c = np.abs(np.array(answers['C']) - np.array(user_csv['C']))\n",
    "    hit_rate_c = np.int64(delta_c < 0.02)\n",
    "    # Температура металла.\n",
    "    delta_t = np.abs(np.array(answers['TST']) - np.array(user_csv['TST']))\n",
    "    hit_rate_t = np.int64(delta_t < 20)\n",
    "\n",
    "    N = np.size(answers['C'])\n",
    "\n",
    "    return np.sum(hit_rate_c + hit_rate_t) / 2 / N\n",
    "\n",
    "\n",
    "def median_absolute_percentage_error(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return np.median(np.abs(y_pred-y_true)/y_true)\n",
    "\n",
    "\n",
    "def metrics_stat(y_true: np.array, y_pred: np.array) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Вывод основных метрик.\n",
    "    :param y_true: np.array, реальные значения целевой переменной.\n",
    "    :param y_pred: np.array, предсказанные значения целевой переменной.\n",
    "    :return: dict, словарь с названиями метрик и значениями\n",
    "    \"\"\"\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    mdape = median_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'mape': mape, 'mdape': mdape, 'rmse': rmse, 'r2': r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Пайплайн (классические модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "lb = LabelEncoder().fit(x_train['building_type'].values)\n",
    "\n",
    "x_train['building_type'] = lb.transform(x_train['building_type'].values)\n",
    "x_test['building_type'] = lb.transform(x_test['building_type'].values)\n",
    "\n",
    "\n",
    "def hyperopt(estimator, params):\n",
    "    column_transformer = ColumnTransformer(  # OHE for cat, Scaler for real\n",
    "        transformers=[\n",
    "            ('real', StandardScaler(), real_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "\n",
    "        ], n_jobs=4\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(  # column transformer and then model\n",
    "        steps=[\n",
    "            ('column_transformer', column_transformer),\n",
    "            ('model', estimator)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=params,\n",
    "        scoring=scorer,\n",
    "        cv=3,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    # write best params to `best_params`\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "\n",
    "    column_transformer = ColumnTransformer(  # OHE for cat, Scaler for real\n",
    "        transformers=[\n",
    "            ('real', StandardScaler(), real_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "\n",
    "        ], n_jobs=4\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(  # column transformer and then model with `best_params` as params\n",
    "        steps=[\n",
    "            ('column_transformer', column_transformer),\n",
    "            ('model', estimator)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.set_params(**best_params)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "    score_train = mape(y_train, pipeline.predict(x_train))\n",
    "    score_test = mape(y_test, pipeline.predict(x_test))\n",
    "\n",
    "    return score_train, score_test, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'model__n_estimators': [10],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    'model__min_samples_split': [2, 12, 500],\n",
    "    'model__max_depth': [5, 9, 12],\n",
    "    'model__subsample' : [0.5, 0.8, 1],\n",
    "}\n",
    "\n",
    "hyperopt(GradientBoostingRegressor(), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Трансформеры данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    # ('imputer', SimpleImputer(strategy='median')), - можно было бы применить импьютер для заполнения пропусков\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Предобработка данных\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)])\n",
    "\n",
    "# Основной pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# Отобразить pipeline\n",
    "set_config(display='diagram')\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Параметры модели и преодобработки данных\n",
    "parameters = {\n",
    "    'preprocessor__num__scaler': [StandardScaler(), RobustScaler()],\n",
    "    'classifier__C': [100, 10, 1, 0.1, 0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Подбор параметров\n",
    "X_train, y_train = data[num_cols + cat_cols], data[target_col]\n",
    "cross_val = StratifiedShuffleSplit(n_splits=5,test_size=0.3,random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, parameters, cv=cross_val, scoring='roc_auc').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Лучшие параметры:\", grid.best_params_)\n",
    "print(\"Лучший score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Модель\n",
    "model = CatBoostClassifier(iterations=100, # количество деревьев уменьшено до 100 для ускорения расчетов\n",
    "                           cat_features=cat_cols, # категориальные фичи\n",
    "                           eval_metric='AUC:hints=skip_train~false', # метрика\n",
    "                           verbose=False) # вывод инфорамации\n",
    "\n",
    "# Сетка для подбора параметров\n",
    "grid = {'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "# Поиск лучших параметров\n",
    "grid_search_result = model.grid_search(grid,\n",
    "                                       X=X_train,\n",
    "                                       y=y_train,\n",
    "                                       cv=5,\n",
    "                                       refit=True,\n",
    "                                       shuffle=True,\n",
    "                                       stratified=True,\n",
    "                                       verbose=False,\n",
    "                                       plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoost с лучшими параметрами\n",
    "best_boost = CatBoostClassifier(iterations=100,\n",
    "                                cat_features=cat_cols,\n",
    "                                custom_metric='AUC:hints=skip_train~false',\n",
    "                                verbose=False,\n",
    "                                **grid_search_result['params'])\n",
    "\n",
    "best_boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Результаты кросс-валидации\n",
    "pd.DataFrame(grid_search_result['cv_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Лучшие параметры:\", grid_search_result['params'])\n",
    "print(\"Лучший score:\", 0.8740685544)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пайплайн (нейросеть)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n):\n",
    "    x1 = np.array([i/100+np.random.uniform(-1,3) for i in range(n)]).reshape(n,1)\n",
    "    x2 = np.array([i/100+np.random.uniform(-3,5)+2 for i in range(n)]).reshape(n,1)\n",
    "    x3 = np.array([i/100+np.random.uniform(-6,5)-3 for i in range(n)]).reshape(n,1)\n",
    "\n",
    "    y1= [x1[i]-x2[i]+x3[i]+np.random.uniform(-2,2) for i in range(n)]\n",
    "    y2= [x1[i]+x2[i]-x3[i]+5+np.random.uniform(-1,3) for i in range(n)]\n",
    "    X = np.hstack((x1, x2, x3))\n",
    "    Y = np.hstack((y1, y2))\n",
    "    return X, Y\n",
    "\n",
    "X, Y = create_data(n=450)\n",
    "\n",
    "plt.plot(Y)\n",
    "plt.show()\n",
    "\n",
    "print(\"X:\", X.shape, \"Y:\", Y.shape)\n",
    "in_dim = X.shape[1]\n",
    "out_dim = Y.shape[1]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(X, Y, test_size=0.15)\n",
    "print(\"xtrain:\", xtrain.shape, \"ytrian:\", ytrain.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=in_dim, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(out_dim))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    " \n",
    "model.fit(xtrain, ytrain, epochs=100, batch_size=12, verbose=0)\n",
    " \n",
    "ypred = model.predict(xtest)\n",
    "print(\"y1 MSE:%.4f\" % mean_squared_error(ytest[:,0], ypred[:,0]))\n",
    "print(\"y2 MSE:%.4f\" % mean_squared_error(ytest[:,1], ypred[:,1]))\n",
    "\n",
    "x_ax = range(len(xtest))\n",
    "plt.scatter(x_ax, ytest[:,0],  s=6, label=\"y1-test\")\n",
    "plt.plot(x_ax, ypred[:,0], label=\"y1-pred\")\n",
    "plt.scatter(x_ax, ytest[:,1],  s=6, label=\"y2-test\")\n",
    "plt.plot(x_ax, ypred[:,1], label=\"y2-pred\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for multi-output regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=3, random_state=2)\n",
    "\treturn X, y\n",
    " \n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs))\n",
    "\tmodel.compile(loss='mae', optimizer='adam')\n",
    "\treturn model\n",
    " \n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "\tresults = list()\n",
    "\tn_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\t# define evaluation procedure\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# enumerate folds\n",
    "\tfor train_ix, test_ix in cv.split(X):\n",
    "\t\t# prepare data\n",
    "\t\tX_train, X_test = X[train_ix], X[test_ix]\n",
    "\t\ty_train, y_test = y[train_ix], y[test_ix]\n",
    "\t\t# define model\n",
    "\t\tmodel = get_model(n_inputs, n_outputs)\n",
    "\t\t# fit model\n",
    "\t\tmodel.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "\t\t# evaluate model on test set\n",
    "\t\tmae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\t\t# store result\n",
    "\t\tprint('>%.3f' % mae)\n",
    "\t\tresults.append(mae)\n",
    "\treturn results\n",
    " \n",
    "# load dataset\n",
    "X, y = get_dataset()\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
